{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973}],"dockerImageVersionId":30066,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Guys.\nIn this Notebook we are going to implement a music Genre classification using K-Nearest Neighbors Classifier algorithm. I hope the notebook will be helpful for the begineers starting with Machine Learning as well with the Audio Processing using Machine Learning.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T16:54:34.422199Z","iopub.execute_input":"2023-11-15T16:54:34.422716Z","iopub.status.idle":"2023-11-15T16:54:34.430876Z","shell.execute_reply.started":"2023-11-15T16:54:34.422668Z","shell.execute_reply":"2023-11-15T16:54:34.429638Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}]},{"cell_type":"code","source":"!pip install python_speech_features","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:38.274615Z","iopub.execute_input":"2023-11-15T16:54:38.275042Z","iopub.status.idle":"2023-11-15T16:54:43.050269Z","shell.execute_reply.started":"2023-11-15T16:54:38.275007Z","shell.execute_reply":"2023-11-15T16:54:43.049107Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"^C\n","output_type":"stream"}]},{"cell_type":"code","source":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport scipy.io.wavfile as wav\nfrom python_speech_features import mfcc\nfrom tempfile import TemporaryFile\nimport os\nimport math\nimport pickle\nimport random\nimport operator","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.623107Z","iopub.execute_input":"2023-11-15T16:54:09.623453Z","iopub.status.idle":"2023-11-15T16:54:09.844774Z","shell.execute_reply.started":"2023-11-15T16:54:09.623420Z","shell.execute_reply":"2023-11-15T16:54:09.841630Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3f6ccac99536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpython_speech_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtempfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporaryFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'python_speech_features'"],"ename":"ModuleNotFoundError","evalue":"No module named 'python_speech_features'","output_type":"error"}]},{"cell_type":"code","source":"def distance(instance1, instance2, k):\n    distance = 0\n    mm1 = instance1[0]\n    cm1 = instance1[1]\n    mm2 = instance2[0]\n    cm2 = instance2[1]\n    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n    distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n    distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n    distance -= k\n    return distance","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.847473Z","iopub.status.idle":"2023-11-15T16:54:09.849688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define a function to get distance between feature vectors and find neighbors\ndef getNeighbors(trainingset, instance, k):\n    distances = []\n    for x in range(len(trainingset)):\n        dist = distance(trainingset[x], instance, k) + distance(instance,trainingset[x],k)\n        distances.append((trainingset[x][2], dist))\n    distances.sort(key=operator.itemgetter(1))\n    neighbors = []\n    for x in range(k):\n        neighbors.append(distances[x][0])\n    return neighbors","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.853130Z","iopub.status.idle":"2023-11-15T16:54:09.855164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* trainingset is actual training data and k is hyperparameter of how much nearest neighbors we want.\n* first part itera gets distances of alll the points in training set\n* we sort the data and get the nearest neighbor, as the data is sorted so it will easily take the k nearest neighbors. and we finally return those neighbors","metadata":{}},{"cell_type":"code","source":"#function to identify the nearest neighbors\ndef nearestclass(neighbors):\n    classVote = {}\n    \n    for x in range(len(neighbors)):\n        response = neighbors[x]\n        if response in classVote:\n            classVote[response] += 1\n        else:\n            classVote[response] = 1\n            \n    sorter = sorted(classVote.items(), key=operator.itemgetter(1), reverse=True)\n    return sorter[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.858513Z","iopub.status.idle":"2023-11-15T16:54:09.860592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* here we define a set, which will help to take the reponse of each class present in nearest neighbors.\n* actually the idea behind this function is that, we already have a list of nearest neighbors and as data is labelled data so each neighbor will hold some particular class, now from that nearest neighbor whatever the maximum frequency will be there for each class, to that class the new data will be assigned.\n* eg- k=10, so will have the list of 10 nearest neighbor, suppose(Class A=4, B=3, C=3) so new point will be assigned to A as of maximum frequency. ","metadata":{}},{"cell_type":"code","source":"# define a function that will evaluate a model\ndef getAccuracy(testSet, prediction):\n    correct = 0\n    for x in range(len(testSet)):\n        if testSet[x][-1] == prediction[x]:\n            correct += 1\n    return 1.0 * correct / len(testSet)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.863184Z","iopub.status.idle":"2023-11-15T16:54:09.865913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa, IPython\nimport librosa.display\nfile = '../input/gtzan-dataset-music-genre-classification/Data/genres_original/disco/disco.00031.wav'\nsignal, sr = librosa.load(file , sr = 22050) \nIPython.display.Audio(signal, rate=sr)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.867081Z","iopub.status.idle":"2023-11-15T16:54:09.871168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory = '../input/gtzan-dataset-music-genre-classification/Data/genres_original'\nf = open(\"my.dat\", \"wb\")\ni = 0\nfor folder in os.listdir(directory):\n    #print(folder)\n    i += 1\n    if i == 11:\n        break\n    for file in os.listdir(directory+\"/\"+folder):\n        #print(file)\n        try:\n            (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n            mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n            mean_matrix = mfcc_feat.mean(0)\n            feature = (mean_matrix, covariance, i)\n            pickle.dump(feature, f)\n        except Exception as e:\n            print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.872370Z","iopub.status.idle":"2023-11-15T16:54:09.873031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* after the cell run we will be having a my.dat file as a collection of different files irrespective of a jonar.\n* we pich each file from genre and calculate rate and signature.\n* what we have done is, we find the imp feature as mfcc(mel frequency celestral coefficients) then we find the feature and then we dump the feature into my.dat file.\n* Now we have a dataset, so we will split into train and test set","metadata":{}},{"cell_type":"code","source":"#split dataset into train and test set\ndataset = []\n\ndef loadDataset(filename, split, trset, teset):\n    with open('my.dat','rb') as f:\n        while True:\n            try:\n                dataset.append(pickle.load(f))\n            except EOFError:\n                f.close()\n                break\n    for x in range(len(dataset)):\n        if random.random() < split:\n            trset.append(dataset[x])\n        else:\n            teset.append(dataset[x])\n\ntrainingSet = []\ntestSet = []\nloadDataset('my.dat', 0.66, trainingSet, testSet)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.874066Z","iopub.status.idle":"2023-11-15T16:54:09.874751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* we will load the dataset again to split it, we take 75% as train and 25% as test data.\n* we split the dataset based on split value, because directly splitting will not give as good result because we want the random sample which is the mix of all the jonars.","metadata":{}},{"cell_type":"code","source":"# Make the prediction using KNN(K nearest Neighbors)\nlength = len(testSet)\npredictions = []\nfor x in range(length):\n    predictions.append(nearestclass(getNeighbors(trainingSet, testSet[x], 5)))\n\naccuracy1 = getAccuracy(testSet, predictions)\nprint(accuracy1)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.882414Z","iopub.status.idle":"2023-11-15T16:54:09.883143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nresults = defaultdict(int)\n\ndirectory = \"../input/gtzan-dataset-music-genre-classification/Data/genres_original\"\n\ni = 1\nfor folder in os.listdir(directory):\n    results[i] = folder\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.884173Z","iopub.status.idle":"2023-11-15T16:54:09.884826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = nearestclass(getNeighbors(dataset, feature, 5))\nprint(results[pred])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:54:09.885794Z","iopub.status.idle":"2023-11-15T16:54:09.886475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## End Note\n\nProcessing Audio Data is way more complex then the image processing at current scenarios. But Python has a great libraries by the help of which we can extract the audio features and analyze them on different scale as time domain. So I hope you like this particular implementation.\n\nPlease If I was able to help you a little bit then upvote this Notebook. Its to much appreciating for me to move forward in my data science carrer.\n\n**Thank You!..**","metadata":{}}]}